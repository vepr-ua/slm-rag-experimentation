# Environment Configuration for slm-rag-experimentation

# ============================================================================
# Database Configuration
# ============================================================================

# SurrealDB connection
SURREALDB_URL=ws://localhost:8001/rpc
SURREALDB_NAMESPACE=experimentation
SURREALDB_DATABASE=knowledge
SURREALDB_USERNAME=root
SURREALDB_PASSWORD=root

# ============================================================================
# LLM Configuration
# ============================================================================

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b  # Options: llama3.2:3b, phi3:3.8b, qwen2.5:3b

# Alternative: OpenAI-compatible API
# LLM_API_BASE_URL=http://localhost:8000/v1
# LLM_API_KEY=your-api-key-here
# LLM_MODEL=gpt-4

# ============================================================================
# Embeddings Configuration
# ============================================================================

# Sentence Transformers model for embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2  # Fast and good quality
# EMBEDDING_MODEL=all-mpnet-base-v2  # Higher quality, slower

# Embedding dimensions (depends on model)
EMBEDDING_DIM=384  # for all-MiniLM-L6-v2
# EMBEDDING_DIM=768  # for all-mpnet-base-v2

# Cache embeddings locally
EMBEDDING_CACHE_DIR=./data/embeddings/cache

# ============================================================================
# API Configuration
# ============================================================================

# FastAPI server
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true  # Auto-reload on code changes (dev only)

# CORS settings
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]

# ============================================================================
# RAG Configuration
# ============================================================================

# Context window settings
MAX_CONTEXT_TOKENS=2048
MAX_RETRIEVED_DOCS=10

# Graph traversal settings
MAX_GRAPH_DEPTH=3
MIN_RELATIONSHIP_STRENGTH=0.3

# ============================================================================
# Data Processing
# ============================================================================

# Chunk size for document processing (in characters)
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Maximum documents to process in parallel
MAX_PARALLEL_PROCESSING=4

# ============================================================================
# Data Collection Configuration
# ============================================================================

# StackExchange (Cross Validated) API
# Get your key at: https://stackapps.com/apps/oauth/register
STACKEXCHANGE_API_KEY=  # Optional: increases rate limit from 300 to 10,000 req/day
STACKEXCHANGE_SITE=stats  # Cross Validated site

# StackExchange collection settings (optional overrides)
# STACKEXCHANGE_MIN_SCORE=5
# STACKEXCHANGE_MAX_QUESTIONS=500
# REQUESTS_PER_MINUTE=10

# ArXiv API settings
ARXIV_DELAY_SECONDS=3.0  # Delay between requests (respect API etiquette)
# ARXIV_MAX_RESULTS_PER_QUERY=50

# Anthropic Claude API (for synthetic Q&A generation)
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=  # Required for synthetic generation
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_MAX_TOKENS=4096

# ============================================================================
# Logging
# ============================================================================

LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=text  # text or json
LOG_FILE=logs/app.log

# ============================================================================
# Development
# ============================================================================

# Enable debug mode
DEBUG=true

# Profile performance
PROFILE=false

# Cache query results
ENABLE_CACHE=true
CACHE_TTL=3600  # seconds

